{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\qquad$ $\\qquad$$\\qquad$  **TDA 231 Machine Learning: Homework 2** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$ **Goal: Classification**<br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Grader: Divya** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                     **Due Date: 23/4** <br />\n",
    "$\\qquad$ $\\qquad$$\\qquad$                   **Submitted by:  Victor Christoffersson, 9312155576, vicchri@student.chalmers.se & Jacob Lundberg, 9409249233, jacobtu@student.chalmers.se ** <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General guidelines:\n",
    "* All solutions to theoretical problems, can be submitted as a single file named *report.pdf*. They can also be submitted in this ipynb notebook, but equations wherever required, should be formatted using LaTeX math-mode.\n",
    "* All discussion regarding practical problems, along with solutions and plots should be specified here itself. We will not generate the solutions/plots again by running your code.\n",
    "* Your name, personal number and email address should be specified above and also in your file *report.pdf*.\n",
    "* All datasets can be downloaded from the course website.\n",
    "* All tables and other additional information should be included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical problems\n",
    "\n",
    "## [Naive Bayes Classifier, 6 points]\n",
    "\n",
    "A psychologist does a small survey on ''happiness''. Each respondent provides a vector with entries 1 or 0 corresponding to if they answered “yes” or “no” to a question respectively. The question vector has attributes \n",
    "$$\n",
    "x = (\\mbox{rich, married, healthy}) \\tag{1}\n",
    "$$\n",
    "\n",
    "Thus a response $(1, 0, 1)$ would indicate that the respondent was\n",
    "''rich'', ''unmarried'' and ''healthy''. In addition, each respondent\n",
    "gives a value $c = 1$ if they are content wih their life and $c = 0$\n",
    "if they’re not. The following responses were obtained.\n",
    "\n",
    "$$\n",
    "c = 1: (1, 1, 1),(0, 0, 1),(1, 1, 0),(1, 0, 1) \\\\\n",
    "c = 0: (0, 0, 0),(1, 0, 0),(0, 0, 1),(0, 1, 0)\n",
    "$$\n",
    "\n",
    "1. Using naive Bayes, what is the probability that a person is ''not rich'', ''married'' and ''healthy'' is ''content''?\n",
    "\n",
    "2. What is the probability that a person who is ''not rich'' and ''married'' is content ? (i.e. we do not know if they are ''healthy'')\n",
    "\n",
    "## Solution\n",
    "\n",
    "### 1.\n",
    "\n",
    "\n",
    "create likelihood table from the data:\n",
    "         total | given content \n",
    "~rich:   4/8     1/4 \n",
    "married: 3/8     2/4\n",
    "healthy: 4/8     3/4\n",
    "content: 4/8\n",
    "         \n",
    "Use bayes to calculate posterior prob for each class\n",
    "\n",
    "Posterior = prior * likelihood / evidence\n",
    "\n",
    "we want P(content|~rich,married,healthy) = P(~rich,married,healthy|content) * P(content) / P(~rich,married,healthy) \n",
    "which because of independence is equal to 1/Z * P(content) * P(~rich|content) * P(married|content) * P(healthy|content)\n",
    "\n",
    "P(~rich,married,healthy|content) = P(~rich|content) * P(married|content) * P(healthy|content) = 1/4 * 2/4 * 3/4 = 3/32\n",
    "\n",
    "P(content) = 4/8\n",
    "\n",
    "Z = P(content)* p(~rich|content) * P(married|content) * P(healthy|content) + P(~content) * p(~rich|~content) * P(married|~content) * P(healthy|~content) = 4/8 * 3/32 + 4/8 * 3/4 * 1/4 * 1/4 = 9/128\n",
    "\n",
    "using this we get: 3/32 * 4/8 / 9/128 = 2/3\n",
    "\n",
    "### 2.\n",
    "Just use the same rules as above except don't factor in healthiness, works because of independence\n",
    "\n",
    "P(content|~rich,married) = P(~rich,married|content) * P(content) / P(~rich,married) = 1/Z * P(content) * P(~rich|content) * P(married|content)\n",
    "\n",
    "P(~rich,married|content) = P(~rich|content) * P(married|content) = 1/4 * 2/4 = 1/8\n",
    "\n",
    "P(content) = 4/8\n",
    "\n",
    "With Z = P(content)* p(~rich|content) * P(married|content) + P(~content) * p(~rich|~content) * P(married|~content) = 1/16 + 3/32 = 5/32\n",
    "\n",
    "and finally: 1/8 * 4/8 / 5/32 = 2/5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## [Extending Naive Bayes, 4 points]\n",
    "\n",
    "Consider now, the following vector of attributes:\n",
    "\n",
    "* $x_1 = 1$ if customer is younger than 20 and 0 otherwise.\n",
    "* $x_2 = 1$ if customer is between 20 and 30 in age, and 0 otherwise.\n",
    "* $x_3 = 1$ if customer is older than 30 and 0 otherwise\n",
    "* $x_4 = 1$ if customer walks to work and 0 otherwise.\n",
    "\n",
    "Each vector of attributes has a label ''rich'' or ''poor''. Point out potential difficulties with your approach above to training using naive Bayes. Suggest and describe how to extend your naive Bayes method to this dataset.\n",
    "\n",
    "X_1, x_2 and x_3 are not independent of each other, they are constrained by x_1 + x_2 + x_3 = 1\n",
    "you can instead extend naive bayes to use one variable for x_1, x_2 and x_3 that can take the value 0, 1 and 2 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical problems\n",
    "\n",
    "## [Bayes classifier, 5 points]\n",
    "\n",
    "Dowload the dataset **\"dataset2.txt\"**. You can use the following code for example:\n",
    "```python\n",
    "from numpy import genfromtxt\n",
    "data = genfromtxt('dataset2.txt', delimiter=',')\n",
    "labels = data[:,-1]\n",
    "```\n",
    "The dataset contains $3$-dimensional data, $X$, generated from $2$ classes with labels, $y$ either $+1$ or $-1$.  Each row of $X$ and $y$ contain one observation and one label respectively.  There are $1000$ instances of each class. \n",
    "\n",
    "a. Assume that the class conditional density is spherical Gaussian, and both classes have equal prior. Write the expression for the Bayes (<span style=\"color:red\"> not **naive Bayes**</span>) classifier i.e. derive\n",
    "$$\n",
    "P(y_{new} = -1 | x_{new} , X, y ) \\\\\n",
    "P(y_{new} = +1 | x_{new} , X, y ) ~.\n",
    "$$\n",
    "\n",
    "It is useful to note that the dependence on training data $X, y$ for class $1$ can be expressed as: \n",
    "\n",
    "$$ \n",
    "P( x_{new} | y_{new} = 1, X, y) = P(x_{new} |\n",
    "\\hat{\\mu}_{1}, \\hat{\\sigma}^{2}_{1})\n",
    "$$\n",
    "\n",
    "where $\\hat{\\mu}_{1} \\in \\mathbb{R}^3$ and $\\hat{\\sigma}^{2}_{1}\\in \\mathbb{R}$ are MLE estimates for mean (3-dimensional) and variance based on training data with label $+1$ (and similarly for class 2 with label $-1$). \n",
    "\n",
    "b. Implement a function **sph_bayes()** which computes the probability of a new test point *Xtest* coming from class $1$ ($P1$) and class $2$ ($P2$). Finally, assign a label *Ytest* to the test point based on the probabilities $P1$ and $P2$.\n",
    "\n",
    "```python\n",
    "def sph_bayes(Xtest, ...): # other parameters needed.\n",
    "\n",
    "    return [P1, P2, Ytest]\n",
    "```\n",
    "c. Write a function **new_classifier()**\n",
    "\n",
    "```python\n",
    "def new_classifier(Xtest, mu1, mu2)\n",
    "    \n",
    "    return [Ytest]\n",
    "```\n",
    "which implements the following classifier,\n",
    "$$\n",
    "f(x) = \\mbox{sign}\\left(\\frac{(\\mu_1 - \\mu_2)^\\top (x - b) }{\\|\\mu_1 -  \\mu_2\\|_2} \\right)\n",
    "$$\n",
    "with $b = \\frac{1}{2}(\\mu_1 + \\mu_2)$.\n",
    "\n",
    "d. Report 5-fold cross validation error for both classifiers.\n",
    "\n",
    "## Solution\n",
    "\n",
    "### a.\n",
    "$$\n",
    "P(y_{new} = -1 | x_{new} , X, y ) = \\frac{P(y_{new} = -1) * P(x_{new}| y_{new} = -1, X, y)}{P(x_{new}, X, y)} = \\frac{P(y_{new} = -1) * P(x_{new}| y_{new} = -1, X, y)}{\\Sigma_j P(x_{new}| y_{new} = j, X, y)P(y_{new} = j)} \\\\\n",
    "$$\n",
    "$$\n",
    "P(y_{new} = +1 | x_{new} , X, y ) = \\frac{P(y_{new} = +1) * P(x_{new}| y_{new} = +1, X, y)}{P(x_{new}, X, y)} = \\frac{P(y_{new} = +1) * P(x_{new}| y_{new} = +1, X, y)}{\\Sigma_j P(x_{new}| y_{new} = j, X, y)P(y_{new} = j)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: 0 [   0    1    2 ... 1996 1997 1999] TEST: [   4    7   13   14   27   28   31   39   44   46   47   48   56   57\n",
      "   58   60   65   68   76   82   84   92   93   95  102  103  104  105\n",
      "  110  111  113  115  121  130  133  135  145  155  170  175  178  186\n",
      "  188  195  197  208  219  223  225  226  227  230  234  244  258  262\n",
      "  263  267  270  271  272  276  283  284  285  287  307  310  315  316\n",
      "  318  324  330  332  336  341  347  355  356  361  365  366  368  377\n",
      "  378  381  383  394  397  409  414  421  427  428  429  431  435  449\n",
      "  453  460  461  466  467  474  490  491  495  504  509  512  516  536\n",
      "  538  543  550  555  567  571  589  594  615  624  626  632  633  641\n",
      "  645  647  650  659  661  664  666  673  675  682  684  685  687  697\n",
      "  701  702  704  706  709  711  714  719  723  731  738  748  750  751\n",
      "  753  762  764  769  780  781  786  801  815  817  822  823  832  835\n",
      "  838  845  854  855  859  860  863  871  873  879  881  887  889  900\n",
      "  907  909  917  920  921  925  934  942  946  949  954  956  958  966\n",
      "  967  968  977  979  989  992  997 1004 1011 1015 1018 1020 1025 1031\n",
      " 1041 1044 1051 1063 1066 1067 1071 1077 1079 1083 1084 1093 1101 1103\n",
      " 1106 1111 1112 1116 1124 1128 1129 1134 1137 1139 1144 1145 1146 1150\n",
      " 1157 1159 1170 1177 1180 1184 1187 1192 1195 1199 1200 1201 1207 1213\n",
      " 1216 1221 1230 1234 1235 1240 1246 1261 1271 1277 1293 1302 1304 1305\n",
      " 1313 1315 1323 1327 1334 1337 1348 1354 1355 1360 1365 1371 1372 1385\n",
      " 1395 1398 1404 1415 1423 1428 1432 1439 1449 1452 1456 1458 1459 1480\n",
      " 1486 1494 1501 1502 1521 1522 1526 1534 1554 1555 1556 1561 1562 1563\n",
      " 1571 1573 1577 1579 1580 1583 1586 1589 1590 1592 1593 1594 1617 1628\n",
      " 1634 1636 1639 1644 1647 1654 1658 1659 1665 1668 1682 1687 1693 1697\n",
      " 1707 1710 1716 1726 1727 1729 1732 1735 1742 1746 1755 1756 1762 1777\n",
      " 1779 1780 1785 1790 1796 1801 1809 1814 1817 1818 1826 1832 1839 1842\n",
      " 1844 1858 1860 1862 1863 1867 1877 1886 1887 1891 1897 1900 1901 1906\n",
      " 1908 1915 1919 1920 1924 1927 1928 1934 1935 1937 1942 1945 1948 1962\n",
      " 1965 1967 1969 1970 1975 1981 1982 1998]\n",
      "TRAIN: 0 [   0    2    3 ... 1997 1998 1999] TEST: [   1    5   12   29   43   67   80   83  100  106  112  116  117  118\n",
      "  123  124  127  136  138  143  158  159  163  174  177  181  184  185\n",
      "  192  193  196  202  204  209  212  214  229  232  235  237  238  241\n",
      "  243  246  249  253  256  259  264  265  277  278  279  280  282  288\n",
      "  291  292  296  303  304  305  320  322  337  346  349  351  375  376\n",
      "  389  396  399  406  410  418  432  436  438  439  440  444  446  450\n",
      "  462  471  477  479  485  487  493  496  498  499  501  506  507  513\n",
      "  517  519  520  528  544  552  557  561  566  568  573  574  576  582\n",
      "  586  595  601  606  611  620  627  628  635  636  638  642  644  654\n",
      "  663  665  670  674  677  678  686  689  693  698  699  705  712  716\n",
      "  718  722  725  732  744  747  752  756  763  776  783  785  798  800\n",
      "  813  818  819  825  829  833  840  842  844  865  872  883  886  890\n",
      "  891  897  908  924  926  927  948  951  952  955  960  961  965  969\n",
      "  972  974  976  994  999 1001 1006 1009 1010 1014 1017 1028 1033 1039\n",
      " 1046 1054 1080 1081 1090 1091 1096 1108 1109 1110 1113 1117 1118 1121\n",
      " 1125 1126 1131 1140 1147 1148 1151 1156 1163 1164 1172 1181 1182 1183\n",
      " 1193 1196 1198 1205 1208 1212 1220 1228 1229 1231 1247 1249 1253 1257\n",
      " 1258 1268 1273 1286 1300 1301 1306 1310 1314 1329 1335 1341 1345 1362\n",
      " 1363 1376 1386 1389 1390 1399 1401 1406 1407 1413 1421 1422 1425 1426\n",
      " 1430 1434 1437 1444 1445 1450 1454 1455 1457 1460 1461 1462 1463 1473\n",
      " 1477 1481 1482 1483 1488 1495 1497 1504 1505 1509 1512 1513 1515 1519\n",
      " 1523 1531 1535 1539 1547 1550 1564 1566 1568 1575 1585 1587 1596 1601\n",
      " 1603 1605 1613 1614 1623 1629 1632 1643 1646 1652 1655 1657 1661 1663\n",
      " 1664 1666 1671 1673 1674 1676 1677 1681 1684 1686 1688 1692 1699 1701\n",
      " 1702 1706 1712 1713 1717 1725 1728 1730 1739 1743 1751 1758 1764 1771\n",
      " 1776 1781 1787 1788 1794 1802 1806 1807 1808 1811 1816 1819 1821 1823\n",
      " 1827 1828 1831 1834 1838 1840 1854 1857 1861 1864 1865 1869 1870 1874\n",
      " 1881 1884 1889 1895 1896 1899 1910 1918 1921 1929 1931 1932 1951 1964\n",
      " 1966 1972 1979 1987 1988 1991 1993 1996]\n",
      "TRAIN: 0 [   0    1    4 ... 1997 1998 1999] TEST: [   2    3    6    8   18   25   30   34   36   45   51   54   61   66\n",
      "   71   72   73   74   75   79   86   89   90   91   94  109  114  119\n",
      "  125  134  148  157  161  162  169  171  176  179  182  189  199  201\n",
      "  203  207  211  213  215  218  222  239  252  255  260  266  268  269\n",
      "  286  290  293  294  301  311  333  338  339  340  352  357  359  363\n",
      "  364  371  380  382  384  398  405  412  419  422  424  425  426  442\n",
      "  454  457  459  463  469  475  500  508  524  526  531  534  540  547\n",
      "  549  551  554  559  563  564  565  575  577  585  587  590  592  596\n",
      "  602  607  608  609  610  613  614  618  619  622  625  639  643  649\n",
      "  652  655  657  660  662  667  668  671  680  691  695  696  708  710\n",
      "  717  720  721  727  729  734  736  737  739  740  741  749  757  759\n",
      "  765  777  782  784  787  790  791  795  797  799  803  805  809  814\n",
      "  816  820  821  824  826  836  846  847  848  852  857  861  866  874\n",
      "  880  884  885  895  898  906  911  912  914  915  916  922  923  939\n",
      "  940  947  950  957  959  964  971  981  986  987  990  993 1002 1003\n",
      " 1005 1012 1016 1022 1026 1027 1034 1042 1043 1048 1052 1053 1057 1064\n",
      " 1072 1078 1082 1085 1087 1089 1092 1094 1097 1104 1114 1138 1141 1153\n",
      " 1155 1158 1161 1162 1169 1171 1176 1178 1179 1186 1202 1203 1204 1206\n",
      " 1210 1214 1215 1224 1225 1226 1233 1237 1256 1260 1262 1266 1270 1276\n",
      " 1278 1282 1283 1285 1287 1294 1297 1298 1316 1320 1321 1322 1325 1326\n",
      " 1333 1343 1350 1351 1356 1369 1375 1380 1387 1400 1402 1409 1410 1414\n",
      " 1417 1424 1440 1441 1446 1448 1466 1469 1472 1474 1484 1485 1489 1499\n",
      " 1503 1514 1524 1532 1536 1541 1545 1557 1559 1567 1570 1576 1578 1582\n",
      " 1588 1591 1598 1599 1607 1609 1610 1615 1616 1618 1624 1635 1645 1650\n",
      " 1653 1675 1680 1689 1694 1695 1698 1708 1709 1711 1715 1719 1736 1738\n",
      " 1741 1750 1760 1763 1765 1768 1769 1774 1782 1784 1792 1793 1799 1803\n",
      " 1820 1829 1835 1836 1843 1848 1849 1850 1853 1855 1859 1866 1868 1871\n",
      " 1879 1882 1890 1893 1904 1905 1909 1912 1913 1916 1922 1925 1939 1940\n",
      " 1943 1946 1953 1954 1955 1957 1983 1985]\n",
      "TRAIN: 0 [   1    2    3 ... 1993 1996 1998] TEST: [   0    9   10   11   21   24   26   35   38   41   42   52   59   62\n",
      "   64   81   96   97   98   99  101  107  108  120  128  129  132  140\n",
      "  141  142  144  149  150  151  153  154  165  168  180  187  190  198\n",
      "  200  210  216  221  228  245  257  273  274  275  281  295  297  299\n",
      "  300  308  309  312  314  319  321  323  325  326  327  334  343  353\n",
      "  362  367  372  373  386  388  390  392  393  400  401  402  403  404\n",
      "  411  415  416  417  423  437  441  443  445  451  465  468  472  473\n",
      "  478  481  482  483  486  492  494  505  511  514  515  518  521  523\n",
      "  525  527  532  537  539  541  545  548  553  560  562  570  578  579\n",
      "  580  581  583  584  588  591  593  597  598  600  603  623  630  634\n",
      "  640  646  648  651  658  672  676  688  692  700  703  715  724  728\n",
      "  733  742  743  746  758  761  766  767  771  772  773  788  792  793\n",
      "  796  802  804  807  808  811  830  831  834  837  851  867  868  870\n",
      "  878  882  888  892  893  902  903  904  910  913  919  928  929  930\n",
      "  932  937  944  962  970  973  975  978  980  985  991  996 1000 1007\n",
      " 1019 1023 1024 1029 1035 1055 1058 1061 1062 1065 1068 1069 1070 1074\n",
      " 1075 1088 1095 1098 1099 1100 1105 1107 1115 1119 1123 1127 1130 1133\n",
      " 1135 1143 1149 1152 1165 1166 1174 1175 1194 1197 1217 1218 1219 1227\n",
      " 1236 1238 1239 1245 1248 1250 1251 1263 1274 1275 1281 1288 1290 1291\n",
      " 1292 1303 1311 1324 1330 1332 1339 1346 1349 1353 1358 1359 1361 1366\n",
      " 1367 1368 1370 1373 1377 1379 1381 1384 1392 1393 1394 1397 1405 1408\n",
      " 1412 1416 1419 1429 1435 1443 1451 1464 1470 1475 1476 1492 1493 1496\n",
      " 1500 1506 1507 1510 1511 1518 1520 1525 1529 1530 1538 1542 1546 1549\n",
      " 1553 1558 1597 1606 1608 1612 1621 1625 1627 1641 1648 1649 1651 1667\n",
      " 1669 1670 1679 1683 1690 1691 1696 1703 1704 1718 1720 1721 1722 1733\n",
      " 1734 1737 1740 1745 1747 1754 1759 1766 1773 1778 1789 1795 1797 1798\n",
      " 1805 1810 1812 1815 1822 1824 1830 1833 1845 1847 1852 1873 1878 1880\n",
      " 1885 1892 1903 1907 1911 1923 1926 1936 1950 1952 1958 1960 1961 1971\n",
      " 1974 1976 1980 1990 1994 1995 1997 1999]\n",
      "TRAIN: 0 [   0    1    2 ... 1997 1998 1999] TEST: [  15   16   17   19   20   22   23   32   33   37   40   49   50   53\n",
      "   55   63   69   70   77   78   85   87   88  122  126  131  137  139\n",
      "  146  147  152  156  160  164  166  167  172  173  183  191  194  205\n",
      "  206  217  220  224  231  233  236  240  242  247  248  250  251  254\n",
      "  261  289  298  302  306  313  317  328  329  331  335  342  344  345\n",
      "  348  350  354  358  360  369  370  374  379  385  387  391  395  407\n",
      "  408  413  420  430  433  434  447  448  452  455  456  458  464  470\n",
      "  476  480  484  488  489  497  502  503  510  522  529  530  533  535\n",
      "  542  546  556  558  569  572  599  604  605  612  616  617  621  629\n",
      "  631  637  653  656  669  679  681  683  690  694  707  713  726  730\n",
      "  735  745  754  755  760  768  770  774  775  778  779  789  794  806\n",
      "  810  812  827  828  839  841  843  849  850  853  856  858  862  864\n",
      "  869  875  876  877  894  896  899  901  905  918  931  933  935  936\n",
      "  938  941  943  945  953  963  982  983  984  988  995  998 1008 1013\n",
      " 1021 1030 1032 1036 1037 1038 1040 1045 1047 1049 1050 1056 1059 1060\n",
      " 1073 1076 1086 1102 1120 1122 1132 1136 1142 1154 1160 1167 1168 1173\n",
      " 1185 1188 1189 1190 1191 1209 1211 1222 1223 1232 1241 1242 1243 1244\n",
      " 1252 1254 1255 1259 1264 1265 1267 1269 1272 1279 1280 1284 1289 1295\n",
      " 1296 1299 1307 1308 1309 1312 1317 1318 1319 1328 1331 1336 1338 1340\n",
      " 1342 1344 1347 1352 1357 1364 1374 1378 1382 1383 1388 1391 1396 1403\n",
      " 1411 1418 1420 1427 1431 1433 1436 1438 1442 1447 1453 1465 1467 1468\n",
      " 1471 1478 1479 1487 1490 1491 1498 1508 1516 1517 1527 1528 1533 1537\n",
      " 1540 1543 1544 1548 1551 1552 1560 1565 1569 1572 1574 1581 1584 1595\n",
      " 1600 1602 1604 1611 1619 1620 1622 1626 1630 1631 1633 1637 1638 1640\n",
      " 1642 1656 1660 1662 1672 1678 1685 1700 1705 1714 1723 1724 1731 1744\n",
      " 1748 1749 1752 1753 1757 1761 1767 1770 1772 1775 1783 1786 1791 1800\n",
      " 1804 1813 1825 1837 1841 1846 1851 1856 1872 1875 1876 1883 1888 1894\n",
      " 1898 1902 1914 1917 1930 1933 1938 1941 1944 1947 1949 1956 1959 1963\n",
      " 1968 1973 1977 1978 1984 1986 1989 1992]\n",
      "[5.638546538457339e-05, 0.9999436145346154, -1]\n",
      "[-1.0]\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import sklearn as sk\n",
    "#from sklearn.model_selection import KFold\n",
    "data = genfromtxt('dataset2.txt', delimiter=',')\n",
    "labels = data[:,-1]\n",
    "\n",
    "data1 = data[:1000,:3]\n",
    "data2 = data[1000:2000,:3]\n",
    "\n",
    "#mean\n",
    "mu1 = np.mean(data1,axis=0)\n",
    "mu2 = np.mean(data2,axis=0)\n",
    "\n",
    "#var\n",
    "sigma1 = np.cov(data1,rowvar=False)\n",
    "sigma2 = np.cov(data2,rowvar=False)\n",
    "\n",
    "def sph_bayes(Xtest, mu1, mu2, sigma1, sigma2):\n",
    "    mvn1 = multivariate_normal(mu1,sigma1)\n",
    "    p1 = mvn1.pdf(Xtest)\n",
    "    mvn2 = multivariate_normal(mu2,sigma2)\n",
    "    p2 = mvn2.pdf(Xtest)\n",
    "    \n",
    "    P1 = p1 / (p1 + p2)\n",
    "    P2 = p2 / (p1 + p2)\n",
    "    \n",
    "    if(P1 > P2):\n",
    "        Ytest = 1\n",
    "    else:\n",
    "        Ytest = -1\n",
    "    return [P1, P2, Ytest]\n",
    "\n",
    "def new_classifier(Xtest, mu1, mu2):\n",
    "    b = (mu1+mu2)/2\n",
    "    muDiff = mu1-mu2\n",
    "    sign = np.sign(muDiff.T.dot(Xtest-b) / np.linalg.norm(muDiff))\n",
    "    Ytest = sign\n",
    "    return [Ytest]\n",
    "\n",
    "kf = sk.model_selection.KFold(5, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(data):\n",
    "    print(\"TRAIN:\",i, train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    #X2_train, X2_test = data2[train_index], data2[test_index]\n",
    "\n",
    "Xtest = np.array([0.3,0.5,0.3])\n",
    "print(sph_bayes(Xtest, mu1, mu2, sigma1, sigma2))\n",
    "print(new_classifier(Xtest,mu1,mu2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [DIGITS dataset classifer, 5 points]\n",
    "\n",
    "Load the DIGITS dataset:\n",
    "```python\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "```\n",
    "This dataset contains $1797$ samples of ten handwritten digit classes. You can further query and visualize the dataset using the various attributes of the returned dictionary:\n",
    "```python\n",
    "data = digits.data\n",
    "print(data.shape)\n",
    "target_names = digits.target_names\n",
    "print (target_names)\n",
    "import matplotlib.pyplot as plt\n",
    "y = digits.target\n",
    "plt.matshow(digits.images[0])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "a. Use **new_classifier()** designed previously to do binary classification between classes representing digits \"*5*\" and \"*8*\".\n",
    "\n",
    "b. Investigate an alternative feature function as described below:\n",
    "\n",
    "1. Scale each pixel value to range $[0, 1] $ from original gray-scale ($0-255$). \n",
    "2. Compute variance of each row and column of the image. This will give you a new feature vector of size $16$ i.e. \n",
    "\n",
    "$$ \n",
    "x' = \\left[ \\; Var(row_1)  , Var(row_2), \\ldots , Var(row_{8}), Var(col_1), \\ldots, Var(col_{8}) \\;\\right]^T\n",
    "$$\n",
    "\n",
    "c. Report $5$-fold cross validation results for parts $(a)$ and\n",
    "$(b)$ in a single table. What can you say about the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
